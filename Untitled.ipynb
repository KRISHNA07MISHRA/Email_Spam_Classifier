{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6873d0af-137b-499f-a0c8-a70f73c841cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa843d6-af84-4af6-bc8b-a4491f0049f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.4/11.0 MB 20.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.9/11.0 MB 9.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.5/11.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.8/11.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 5.7 MB/s  0:00:01\n",
      "Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.8 MB 8.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.8 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.1/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 4.8 MB/s  0:00:02\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.3 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7c17b8-5e21-4259-b918-934f6a304bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a295ed-96e3-4dcf-b486-611312a4a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1a2b43-0d27-4721-9b64-261f194d68a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e673d61f-2692-4256-bcee-b32624c34fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8d23e-c0cd-4c1c-99bb-1246fa9a590a",
   "metadata": {},
   "source": [
    "This process is similar to converting text into token IDs.\n",
    "\n",
    "However, instead of using the GPT vocabulary, which consists of more than 50,000 words, we are dealing with just two token IDs: 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d651225-6f69-498c-8caa-2d525d7dd9fb",
   "metadata": {},
   "source": [
    "We create a random_split function to split the dataset into three parts: 70% for training, 10% for validation, and 20% for testing.\n",
    "\n",
    "(These ratios are common in machine learning to train, adjust, and evaluate models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a42a3eb-c18e-439e-b0a6-22d098c9f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d7d2db-942f-4dd3-861c-23b3b3f75bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6254620b-fc84-4d0b-bc63-d1abdc5b2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec30306-48fb-44ed-bd57-8558ba032abf",
   "metadata": {},
   "source": [
    "Previously, we utilized a sliding window technique to generate uniformly sized text chunks, which were then grouped into batches for more efficient model training. Each chunk functioned as an individual training instance\n",
    "\n",
    "In the case of email spam classification, have two primary options:\n",
    "\n",
    "(1) Truncate all messages to the length of the shortest message in the dataset or batch.\n",
    "\n",
    "(2) Pad all messages to the length of the longest message in the dataset or batch.\n",
    "\n",
    "Option 1 is computationally cheaper, but it may result in significant information loss if shorter messages are much smaller than the average or longest messages, potentially reducing model performance.\n",
    "\n",
    "So, we opt for the second option, which preserves the entire content of all messages.\n",
    "\n",
    "To implement option 2, where all messages are padded to the length of the longest message in the dataset, we add padding tokens to all shorter messages.\n",
    "\n",
    "For this purpose, we use \"<|endoftext|>\" as a padding token, as discussed in chapter 2.\n",
    "\n",
    "However, instead of appending the string \"<|endoftext|>\" to each of the text messages directly, we can add the token ID corresponding to \"<|endoftext|>\" to the encoded text\n",
    "\n",
    "As we have seen earlier, we first need to implement a PyTorch Dataset, which specifies how the data is loaded and processed, before we can instantiate the data loaders.\n",
    "\n",
    "For this purpose, we define the SpamDataset class.\n",
    "\n",
    "This SpamDataset class handles several key tasks: it identifies the longest sequence in the training dataset, encodes the text messages, and ensures that all other sequences are padded with a padding token to match the length of the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622b94fc-2429-4aac-9399-a7b40190e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.8.0-cp313-cp313-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 3.7/241.3 MB 26.4 MB/s eta 0:00:09\n",
      "    --------------------------------------- 3.9/241.3 MB 19.5 MB/s eta 0:00:13\n",
      "    --------------------------------------- 4.7/241.3 MB 8.1 MB/s eta 0:00:30\n",
      "    --------------------------------------- 6.0/241.3 MB 7.7 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 7.6/241.3 MB 7.7 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 8.4/241.3 MB 7.1 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 9.2/241.3 MB 6.4 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 10.0/241.3 MB 6.0 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 10.7/241.3 MB 5.9 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 11.8/241.3 MB 5.8 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 12.8/241.3 MB 5.7 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 14.4/241.3 MB 5.9 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 15.5/241.3 MB 5.7 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 16.3/241.3 MB 5.6 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 17.6/241.3 MB 5.7 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 18.4/241.3 MB 5.5 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 18.9/241.3 MB 5.4 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 19.7/241.3 MB 5.3 MB/s eta 0:00:43\n",
      "   --- ------------------------------------ 21.0/241.3 MB 5.3 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 22.3/241.3 MB 5.4 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 22.8/241.3 MB 5.3 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 24.1/241.3 MB 5.2 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 25.2/241.3 MB 5.2 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 26.2/241.3 MB 5.3 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 27.0/241.3 MB 5.2 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 28.0/241.3 MB 5.2 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 29.4/241.3 MB 5.2 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 30.1/241.3 MB 5.2 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 31.5/241.3 MB 5.2 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 33.3/241.3 MB 5.3 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 33.8/241.3 MB 5.3 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 34.9/241.3 MB 5.3 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 35.7/241.3 MB 5.2 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 36.7/241.3 MB 5.2 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 37.5/241.3 MB 5.2 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 38.8/241.3 MB 5.2 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 39.8/241.3 MB 5.2 MB/s eta 0:00:39\n",
      "   ------ --------------------------------- 40.9/241.3 MB 5.2 MB/s eta 0:00:39\n",
      "   ------ --------------------------------- 41.7/241.3 MB 5.1 MB/s eta 0:00:39\n",
      "   ------- -------------------------------- 42.7/241.3 MB 5.1 MB/s eta 0:00:39\n",
      "   ------- -------------------------------- 44.0/241.3 MB 5.2 MB/s eta 0:00:39\n",
      "   ------- -------------------------------- 45.1/241.3 MB 5.2 MB/s eta 0:00:39\n",
      "   ------- -------------------------------- 45.4/241.3 MB 5.1 MB/s eta 0:00:39\n",
      "   ------- -------------------------------- 46.1/241.3 MB 5.0 MB/s eta 0:00:39\n",
      "   ------- -------------------------------- 47.4/241.3 MB 5.1 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 49.3/241.3 MB 5.1 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 50.1/241.3 MB 5.1 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 50.6/241.3 MB 5.1 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 51.4/241.3 MB 5.0 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 52.7/241.3 MB 5.1 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 53.7/241.3 MB 5.0 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 55.3/241.3 MB 5.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 56.4/241.3 MB 5.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 56.9/241.3 MB 5.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 57.7/241.3 MB 5.0 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 59.0/241.3 MB 5.0 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 60.6/241.3 MB 5.1 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 61.3/241.3 MB 5.1 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 62.1/241.3 MB 5.1 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 62.9/241.3 MB 5.0 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 64.0/241.3 MB 5.0 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 64.7/241.3 MB 5.0 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 65.8/241.3 MB 5.0 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 67.4/241.3 MB 5.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 68.9/241.3 MB 5.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 69.5/241.3 MB 5.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 70.3/241.3 MB 5.0 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 71.3/241.3 MB 5.0 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 71.8/241.3 MB 5.0 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 73.1/241.3 MB 5.0 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 74.2/241.3 MB 5.0 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 75.0/241.3 MB 5.0 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 76.0/241.3 MB 5.0 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 77.6/241.3 MB 5.0 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 79.2/241.3 MB 5.1 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 80.0/241.3 MB 5.0 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 80.5/241.3 MB 5.0 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 81.0/241.3 MB 5.0 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 81.8/241.3 MB 5.0 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 83.4/241.3 MB 5.0 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 84.7/241.3 MB 5.0 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 85.7/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 86.8/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 87.8/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 88.6/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 89.1/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 90.2/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   --------------- ------------------------ 91.2/241.3 MB 5.0 MB/s eta 0:00:31\n",
      "   --------------- ------------------------ 92.3/241.3 MB 5.0 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 93.3/241.3 MB 5.0 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 94.4/241.3 MB 5.0 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 95.2/241.3 MB 5.0 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 97.0/241.3 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 97.8/241.3 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 98.3/241.3 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 99.1/241.3 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 100.4/241.3 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 101.7/241.3 MB 5.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 102.8/241.3 MB 5.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 103.5/241.3 MB 5.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 5.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 105.4/241.3 MB 5.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 106.7/241.3 MB 5.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 107.7/241.3 MB 5.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 108.8/241.3 MB 5.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 109.6/241.3 MB 5.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 110.9/241.3 MB 5.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 112.2/241.3 MB 5.0 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 113.0/241.3 MB 5.0 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 113.8/241.3 MB 5.0 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 114.6/241.3 MB 5.0 MB/s eta 0:00:26\n",
      "   ------------------- -------------------- 116.1/241.3 MB 5.0 MB/s eta 0:00:26\n",
      "   ------------------- -------------------- 117.4/241.3 MB 5.0 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 118.2/241.3 MB 5.0 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 118.8/241.3 MB 5.0 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 119.5/241.3 MB 5.0 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 121.1/241.3 MB 5.0 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 122.2/241.3 MB 5.0 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 123.2/241.3 MB 5.0 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 124.3/241.3 MB 5.0 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 125.3/241.3 MB 5.0 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 126.4/241.3 MB 5.0 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 127.1/241.3 MB 5.0 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 127.9/241.3 MB 5.0 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 129.2/241.3 MB 5.0 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 130.8/241.3 MB 5.0 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 131.9/241.3 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 132.9/241.3 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 133.4/241.3 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 134.2/241.3 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 135.3/241.3 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 136.6/241.3 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 137.6/241.3 MB 5.0 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 138.4/241.3 MB 5.0 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 139.7/241.3 MB 5.0 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 140.5/241.3 MB 5.0 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 141.8/241.3 MB 5.0 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 143.1/241.3 MB 5.0 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 144.2/241.3 MB 5.0 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 145.5/241.3 MB 5.0 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 146.3/241.3 MB 5.0 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 146.8/241.3 MB 5.0 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 147.3/241.3 MB 5.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 148.1/241.3 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 149.7/241.3 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 151.3/241.3 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 151.8/241.3 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 152.6/241.3 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 153.6/241.3 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 154.4/241.3 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 155.5/241.3 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 156.8/241.3 MB 4.9 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 158.1/241.3 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 158.6/241.3 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 159.4/241.3 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 160.4/241.3 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 161.5/241.3 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 162.8/241.3 MB 4.9 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 164.1/241.3 MB 4.9 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 164.9/241.3 MB 4.9 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 165.9/241.3 MB 4.9 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 167.0/241.3 MB 4.9 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 168.0/241.3 MB 4.9 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 168.8/241.3 MB 4.9 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 169.9/241.3 MB 4.9 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 170.9/241.3 MB 4.9 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 172.2/241.3 MB 4.9 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 173.3/241.3 MB 4.9 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 173.8/241.3 MB 4.9 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 174.6/241.3 MB 4.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 175.6/241.3 MB 4.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 176.7/241.3 MB 4.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 178.0/241.3 MB 4.9 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 179.3/241.3 MB 4.9 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 180.1/241.3 MB 4.9 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 180.6/241.3 MB 4.9 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 181.4/241.3 MB 4.9 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 182.7/241.3 MB 4.9 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 183.8/241.3 MB 4.9 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 184.8/241.3 MB 4.9 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 186.1/241.3 MB 4.9 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 187.4/241.3 MB 4.9 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 188.5/241.3 MB 4.9 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 189.3/241.3 MB 4.9 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 189.8/241.3 MB 4.9 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 190.6/241.3 MB 4.9 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 192.2/241.3 MB 4.9 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 193.7/241.3 MB 4.9 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 194.5/241.3 MB 4.9 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 195.3/241.3 MB 4.9 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 196.1/241.3 MB 4.9 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 196.9/241.3 MB 4.9 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 198.4/241.3 MB 4.9 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 199.0/241.3 MB 4.9 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 200.3/241.3 MB 4.9 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 201.9/241.3 MB 4.9 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 202.6/241.3 MB 4.9 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 203.7/241.3 MB 4.9 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 204.7/241.3 MB 4.9 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 205.5/241.3 MB 4.9 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 206.8/241.3 MB 4.9 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 208.1/241.3 MB 4.9 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 209.2/241.3 MB 4.9 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 210.0/241.3 MB 4.9 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 211.0/241.3 MB 4.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 212.1/241.3 MB 4.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 213.1/241.3 MB 4.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 213.9/241.3 MB 4.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 214.7/241.3 MB 4.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 216.0/241.3 MB 4.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 217.8/241.3 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 218.4/241.3 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 219.2/241.3 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 219.7/241.3 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 221.0/241.3 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 222.0/241.3 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 223.1/241.3 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 223.9/241.3 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 224.9/241.3 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 226.0/241.3 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 227.0/241.3 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 227.8/241.3 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 228.9/241.3 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 230.4/241.3 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 231.2/241.3 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 232.0/241.3 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 233.0/241.3 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 233.8/241.3 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 234.9/241.3 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  235.9/241.3 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  236.7/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  238.0/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  239.3/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  240.4/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.3/241.3 MB 4.8 MB/s  0:00:49\n",
      "Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.6/1.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 7.4 MB/s  0:00:00\n",
      "Downloading torchaudio-2.8.0-cp313-cp313-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 2.1/2.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 8.5 MB/s  0:00:00\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.8/7.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.4/7.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.4/7.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/7.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/7.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 5.0 MB/s  0:00:01\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.4/6.3 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.2 MB/s  0:00:01\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 2.9 MB/s  0:00:00\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.8 MB/s  0:00:00\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---------------------------------------- 0/9 [mpmath]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   -------- ------------------------------- 2/9 [pillow]\n",
      "   -------- ------------------------------- 2/9 [pillow]\n",
      "   -------- ------------------------------- 2/9 [pillow]\n",
      "   -------- ------------------------------- 2/9 [pillow]\n",
      "   -------- ------------------------------- 2/9 [pillow]\n",
      "   -------- ------------------------------- 2/9 [pillow]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ----------------- ---------------------- 4/9 [fsspec]\n",
      "   ----------------- ---------------------- 4/9 [fsspec]\n",
      "   ----------------- ---------------------- 4/9 [fsspec]\n",
      "   ---------------------- ----------------- 5/9 [filelock]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [torch]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ------------------------------- -------- 7/9 [torchvision]\n",
      "   ----------------------------------- ---- 8/9 [torchaudio]\n",
      "   ----------------------------------- ---- 8/9 [torchaudio]\n",
      "   ----------------------------------- ---- 8/9 [torchaudio]\n",
      "   ----------------------------------- ---- 8/9 [torchaudio]\n",
      "   ----------------------------------- ---- 8/9 [torchaudio]\n",
      "   ----------------------------------- ---- 8/9 [torchaudio]\n",
      "   ---------------------------------------- 9/9 [torchaudio]\n",
      "\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 pillow-11.3.0 sympy-1.14.0 torch-2.8.0 torchaudio-2.8.0 torchvision-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee76c35-4509-4c0f-9ad4-236eba0ce267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d3b5e-3fd4-49d1-a9d1-ee2b59d0042d",
   "metadata": {},
   "source": [
    "Step 1: Pre-tokenize texts\n",
    "\n",
    "Step 2: Truncate sequences if they are longer than max_length\n",
    "\n",
    "Step 3: Pad sequences to the longest sequence\n",
    "\n",
    "The SpamDataset class loads data from the CSV files we created earlier, tokenizes the text using the GPT-2 tokenizer from tiktoken and allows us to pad or truncate the sequences to a uniform length determined by either the longest sequence or a predefined maximum length.\n",
    "\n",
    "This ensures each input tensor is of the same size, which is necessary to create the batches in the training data loader we implement next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8964d3b8-1d2d-47a6-8a97-300de3ddee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krishna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 883.9/883.9 kB 13.5 MB/s  0:00:00\n",
      "Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "\n",
      "   -------------------- ------------------- 1/2 [tiktoken]\n",
      "   ---------------------------------------- 2/2 [tiktoken]\n",
      "\n",
      "Successfully installed regex-2025.9.18 tiktoken-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea7a49c-70c1-4acb-a772-2e99ee78d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f10b2e98-3788-4b71-8b12-daafeb95b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2384566-1e37-47de-a8f4-b5899a9f97ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead39bb-edb9-4b37-ad8e-a6ba57bee1a9",
   "metadata": {},
   "source": [
    "The code outputs 120, showing that the longest sequence contains no more than 120 tokens, a common length for text messages.\n",
    "\n",
    "It's worth noting that the model can handle sequences of up to 1,024 tokens, given its context length limit.\n",
    "\n",
    "If your dataset includes longer texts, you can pass max_length=1024 when creating the training dataset in the preceding code to ensure that the data does not exceed the model's supported input (context) length.\n",
    "\n",
    "Next, we pad the validation and test sets to match the length of the longest training sequence.\n",
    "\n",
    "It's important to note that any validation and test set samples exceeding the length of the longest training example are truncated using encoded_text[:self.max_length] in the SpamDataset code we defined earlier.\n",
    "\n",
    "This truncation is optional; you could also set max_length=None for both validation and test sets, provided there are no sequences exceeding 1,024 tokens in these sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "151c0c54-458b-4043-9dd0-807012b0f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0292c0a-b874-4619-9489-4ec203e416be",
   "metadata": {},
   "source": [
    "Using the datasets as inputs, we can instantiate the data loaders similarly to what we did earlier.\n",
    "\n",
    "However, in this case, the targets represent class labels rather than the next tokens in the text.\n",
    "\n",
    "For instance, choosing a batch size of 8, each batch will consist of 8 training examples of length 120 and the corresponding class label of each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd4f9119-36ce-4a83-96f4-fccc1155db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "038d8351-2307-499a-beae-679afc556b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d41a1-34fb-4ac6-9a75-42ded6526d07",
   "metadata": {},
   "source": [
    "As we can see, the input batches consist of 8 training examples with 120 tokens each, as expected.\n",
    "\n",
    "The label tensor stores the class labels corresponding to the 8 training examples.\n",
    "\n",
    "Lastly, to get an idea of the dataset size, let's print the total number of batches in each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "712d85d5-2922-4b19-92a0-4191092e5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a2f6a-1cc4-4c1e-a6e7-acf7bd705e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
